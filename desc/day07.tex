Today was math fundamentals, but still fun for me to derive the respective solutions. For task 1, we can use a somewhat trivial argumentation: Consider the target candidate $x$ to initially lie at $x_0$ somewhere within the field of crabs so that their accumulated distance to $x_0$ is $d_{x_0}$. With this initial value, we can split the crabs into two groups of different size: $L_0$ crabs on the left, and $R_0$ on the right of $x_0$. Moving $x$ one unit to the left will reduce the distance to travel for all $L_0$ crabs by $1$, and increase it by 1 for the other $R_0$ crabs: $d_{x_{0}-1} = d_{x_0}+(R_0-L_0)$. As long as the groups stay the same, the distance just goes up by the difference $(R_0-L_0)$. But if we move past a crab, say, on the left, it now switches from the left to the right group. With each additional step, the total distance to $x$ now increases by $R_0+1$ and decreases by $L_0-1$. The same, but mirrored, is true for moving one step to the right, where we have $d_{x_{0}+1} = d_{x_0}+(L_0-R_0)$. The best location $x^\ast$ to keep $d_{x^\ast}$ as low as possible is thus in a spot where $R = L$: regardless of the exact value for $d_{x^\ast}$, from there, no matter where we move, things can only get worse. If we move left, we eventually get $R > L$ and then $d_{x - 1} = d_{x}+(R-L)$ will grow from there. If we instead move right, we eventually get $L > R$ and $d_{x+1} = d_{x}+(L-R)$ will grow. Hence, the solution for the first task is the median.
<br><br>
For the second solution, I derived it formally. First of all, Gau√ü tells us that $\sum_{d=1}^D = \frac{D^2 +D}{2}$, so given a particular target $x^\ast$, we could compute each crab's fuel expense for moving there from $x$ as $\frac{(x^\ast-x)^2 + |x^\ast-x|}{2}$. Now to find the ideal value $x^\ast$, we want to choose it such that it minimizes the sum of this term over all $N$ crabs, i.e., $\underset{x^\ast}{\text{min}} \sum_i^N \frac{(x^\ast-x_i)^2 + |x^\ast-x_i|}{2}$. 
<br><br>
We can do this by taking the first derivative w.r.t. $x^\ast$ and setting it to 0. If we do this using fundamental differentiation rules and cancelling, we eventually get $\sum_i^N x^\ast - x_i + \frac{\text{sgn}(x^\ast-x_i)}{2} = 0$. The trickiest part here is probably the $\text{sgn}$ function, which returns $1$ for positive inputs, $-1$ for negative and $0$ otherwise. We can move part of this result to the right: $\sum_i^N x^\ast = \sum_i^N x_i - \frac{\text{sgn}(x^\ast-x_i)}{2}$. Since $x^\ast$ doesn't change with $i$, we can replace its sum by multiplication and write $N x^\ast = \sum_i^N x_i - \frac{\text{sgn}(x^\ast-x_i)}{2}$. Dividing by $N$, we get $x^\ast = \frac{1}{N} \sum_i^N x_i - \frac{\text{sgn}(x^\ast-x_i)}{2}$. 
<br><br>
Now $\frac{1}{N}\sum_i^N x_i$ is just the mathematical definition of the mean value over all $x_i$ values, $\hat{x}$. So we get $x^\ast = \hat{x} - \sum_i^N \frac{\text{sgn}(x^\ast-x_i)}{2N}$. All that's left to figure out is $\sum_i^N \frac{\text{sgn}(x^\ast-x_i)}{2}$. This basically comes down to the relationship of the $L,R$ groups again. If $L > R$, then the majority of evaluations of $\text{sgn}(x^\ast-x_i)$ will give $-1$ and their sum will be negative. If $R > L$, the sum will be positive. However, we know that neither $L$ nor $R$ can be bigger than the total number of $N$. And since the sum is divided by $2N$, we can bound the entire expression by the range $(-\frac{1}{2},\frac{1}{2})$. Since the mean computation will probably give us a floating point number, we thus have to check the possible integer values in the range $\lfloor \hat{x} \rceil \pm 1$, i.e., round the mean and test the result, as well as the next integer above and below.