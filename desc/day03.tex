Counting most and least common bits in each position. For the second half, we are filtering a list of $n$ entries of $k$-long bit sequences, according to the most common bit in each place. Filtering is only performed on numbers that have the according value set for the respective bit. As simple as this challenge may seem, I have seen a few arguments that this solution is in fact $\mathcal{O}(n^2)$ and stating that running over the same numbers over and over again is unnecessarily complex. Instead, there should be an $\mathcal{O}(n \log n)$ solution. I have seen a few participants therefore resorting to building a full binary tree (left/right at every bit) or even tries. As far as I can tell, there is some confusion: first, the basic solution is $\mathcal{O}(n \times k)$. Second, regarding full binary tree-based approaches: building a full binary tree will not only make the run time $\mathcal{O}(n \times k)$, it will actually make it $\mathcal{\Omega}(n \times k)$, thus always achieving the same run time as the naive solution in the worst case scenario.
<br><br>
Furthermore, regarding any more advanced tree-based approaches or alternatives, in terms of asymptotic run time I believe it's a wash: any such approach that we could think of can only assume a building time $\mathcal{O}(n \log n)$ if the necessary operations ($<$,$>$ comparisons) are possible in constant time. This is only true if we consider the number of bits to be a constant. But if the number of bits is assumed constant, then the complexity of the original, naive implementation actually drops to  $\mathcal{O}(n)$ and we can't do much better than that. That said, I'd be delighted to be told that my conjecture is wrong and that there actually is a more optimal solution!
<br><br>
It is true that a tree could be reused to compute both target output values. But again, as far as we know, there are only two that we care about, thus this is another constant factor.